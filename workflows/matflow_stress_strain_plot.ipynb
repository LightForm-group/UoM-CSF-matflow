{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MatFlow to generate a stress-strain curve from DAMASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The workflow profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the example uniaxial simulation profile file located [here on GitHuB](https://github.com/LightForm-group/UoM-CSF-matflow/blob/master/workflows/DAMASK/uniaxial_sim.yml). Let's go through the different sections of the workflow file. First of all, we see this block:\n",
    "\n",
    "```yaml\n",
    "name: uniaxial_sim\n",
    "stats: false\n",
    "archive: dropbox\n",
    "run_options:\n",
    "  l: short\n",
    "```\n",
    "\n",
    "The `name` parameter is used when MatFlow generates a directory for the workflow; this directory will be the name, followed by a date and time stamp. Here, `stats` is set to `false`, meaning MatFlow will not run extra accounting jobs to record extra information like the memory usage, which is usually not needed, but might be useful when performing benchmarking. The `archive` key is set in this case to `dropbox`, which is the name of an archive location definition within my `~/.matflow/config.yml` file. Within the config file, the archive location is defined like this:\n",
    "\n",
    "```yaml\n",
    "archive_locations:\n",
    "  dropbox:\n",
    "    cloud_provider: dropbox\n",
    "    path: /matflow/archived\n",
    "```\n",
    "\n",
    "In the above, the `path` key is defined relative to the root directory in my Dropbox account.\n",
    "\n",
    "Finally, `run_options` specifies the default scheduler options that should be used by the tasks. Most of these options are passed directly to the scheduler, with the exception of `num_cores` and `alternate_scratch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look briefly at the tasks defined in this workflow. The first task is:\n",
    "\n",
    "```yaml\n",
    "  - name: generate_microstructure_seeds\n",
    "    method: random\n",
    "    software: damask\n",
    "    base:\n",
    "      grid_size: [16, 16, 16]\n",
    "      num_grains: 100\n",
    "    output_map_options:\n",
    "      phase_label: Al  \n",
    "```\n",
    "\n",
    "This task generates seed positions for the microstructure; these will become the grain centres. The initial RVE discretisation is specified here as well using the `grid_size` option. Notice also the use of the `output_map_options` key. This is used to specify any additional meta information that should be associated with the task output, but that does not actually modify the execution of the task itself. Here, we are using it to tell label the generated microstructure seed positions as belonging to a phase labled by `Al`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second task is to generate the model geometry that will be simulated by DAMASK:\n",
    "    \n",
    "```yaml\n",
    "  - name: generate_volume_element\n",
    "    method: random_voronoi\n",
    "    software: damask\n",
    "    base:\n",
    "      size: [1, 1, 1]\n",
    "```\n",
    "\n",
    "We specify that the volume element should be generated by using a random voronoi tessellation, in this case using the processing tools available in DAMASK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is simply to provide a visualisation of the volume element, in the form of a VTR file, which can be viewed directly within Paraview:\n",
    "    \n",
    "```yaml\n",
    "  - name: visualise_volume_element\n",
    "    method: VTK\n",
    "    software: damask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we need to generate a load case for the simulation, to tell DAMASK by how much to deform the volume element. This task is specified like this:\n",
    "\n",
    "```yaml\n",
    "  - name: generate_load_case\n",
    "    method: uniaxial\n",
    "    software: formable\n",
    "    base:\n",
    "      total_times: [100]\n",
    "      num_increments: [300]\n",
    "      target_strain_rates: [1.0e-3]\n",
    "      directions: [z]\n",
    "```\n",
    "\n",
    "Here, we specify that the loading should be uniaxial in the model z-direction. We also specify for how long loading should continue, and over how many increments DAMASK should partition the load case. Notice that the loading keys specified here are lists, rather than single numbers. This is to support multiple sequential load cases within the same simulation. For instance, we could load first at a strain rate of 1e-3, and then at a strain rate of 1e-4. Alternatively, we might want to increase the number of increments per unit of strain in the elastic-plastic transition region, to make sure we sample the curvature sufficiently well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the task to perform the actual simulation using DAMASK:\n",
    "\n",
    "```yaml\n",
    "  - name: simulate_volume_element_loading\n",
    "    method: CP_FFT\n",
    "    software: DAMASK\n",
    "    run_options:\n",
    "      num_cores: 8\n",
    "      alternate_scratch: /mnt/eps01-rds/Fonseca-Lightform/mbdxqap3/temp-DAMASK\n",
    "    output_map_options:\n",
    "      operations:\n",
    "        - name: add_Cauchy\n",
    "          args: {P: P, F: F}\n",
    "          opts: {add_Mises: true}\n",
    "        - name: add_strain_tensor\n",
    "          args: {F: F, t: V, m: 0}\n",
    "          opts: {add_Mises: true}          \n",
    "        - name: add_strain_tensor\n",
    "          args: {F: Fp, t: V, m: 0}\n",
    "          opts: {add_Mises: true}\n",
    "      incremental_data:\n",
    "        - name: vol_avg_equivalent_stress\n",
    "          path: constituent/1_Al/generic/sigma_vM\n",
    "          transforms: [mean_along_axes: 1]\n",
    "        - name: vol_avg_equivalent_strain\n",
    "          path: constituent/1_Al/generic/epsilon_V^0(F)_vM\n",
    "          transforms: [mean_along_axes: 1]\n",
    "        - name: vol_avg_equivalent_plastic_strain\n",
    "          path: constituent/1_Al/generic/epsilon_V^0(Fp)_vM\n",
    "          transforms: [mean_along_axes: 1]\n",
    "          increments: 10 # Data should be extracted every 10th increment.\n",
    "    base:\n",
    "      homogenization_labels: [SX]\n",
    "      homogenization_schemes:\n",
    "        SX:\n",
    "          mech: none\n",
    "      phases:\n",
    "        Al:\n",
    "          outputs: [F, P, Fp]\n",
    "          tau0_slip: 22e6\n",
    "          tausat_slip: 129e6\n",
    "          h0_slipslip: 573e6\n",
    "          elasticity: hooke\n",
    "          plasticity: phenopowerlaw\n",
    "          lattice_structure: fcc\n",
    "          Nslip: 12\n",
    "          Ntwin: 0\n",
    "          c11: 106.75e9\n",
    "          c12: 60.41e9\n",
    "          c44: 28.34e9\n",
    "          gdot0_slip: 0.001\n",
    "          n_slip: 20\n",
    "          a_slip: 2.25\n",
    "          interaction_slipslip: 1 1 1.4 1.4 1.4 1.4\n",
    "          atol_resistance: 1\n",
    "```\n",
    "\n",
    "There are a few things to note here:\n",
    "- We specify `run_options` here that differ from the default options we specified for all other tasks. This is because the simulation itself is, relatively, computationally expensive, and so requires more CPU cores to complete. Here we specify 8 cores. Another run option is the `alternate_scratch` key, which tells MatFlow to execute this task within a different directory to the MatFlow project directory (which is best to keep on scratch). This is used here because DAMASK cannot run on the CSF's scratch filesystem; yet it is best-practice to run as much computational work as possible on scratch; by specifying the `alternate_scratch` key (here, pointing to a location on our group RDS space), the DAMASK input files will be transparently copied over to the alternate location, and once the simulation is complete, the output files will be copied back to the project directory to allow the workflow to continue.\n",
    "- The `output_map_options` tell MatFlow which data from the DAMASK simulation should be saved into the workflow\n",
    "- There must be a phase listed in the `phases` key that matches the `phase_label` defined in the first task: `generate_microstructure_seeds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting a stress-strain curve from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matflow import load_workflow\n",
    "from plotly import graph_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading matflow config from C:\\Users\\adamj\\.matflow\\config.yml\n",
      "Loading task schemas from 1 file(s)...OK!\n",
      "Loading software definitions from 1 file(s)...OK!\n"
     ]
    }
   ],
   "source": [
    "path = r'/path/to/matflow/project/directory'\n",
    "workflow = load_workflow(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Task(name='generate_microstructure_seeds', method='random', software='damask'),\n",
       " Task(name='generate_volume_element', method='random_voronoi', software='damask'),\n",
       " Task(name='generate_load_case', method='uniaxial', software='formable'),\n",
       " Task(name='visualise_volume_element', method='VTK', software='damask'),\n",
       " Task(name='simulate_volume_element_loading', method='CP_FFT', software='damask')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_elem_resp = workflow.tasks[4].elements[0].outputs.volume_element_response\n",
    "strain = vol_elem_resp['vol_avg_equivalent_strain']['data']\n",
    "stress = vol_elem_resp['vol_avg_equivalent_stress']['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6e31aa07074694b63d283c5107a051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'scatter',\n",
       "              'uid': 'b61604d4-8b30-48b6-8817-0257022c926f',\n",
       " …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_objects.FigureWidget(\n",
    "    data=[{\n",
    "            'x': strain,\n",
    "            'y': stress,\n",
    "    }],\n",
    "    layout={'width': 550, 'xaxis_title': 'Eq. strain', 'yaxis_title': 'Eq. stress'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:matflow_env]",
   "language": "python",
   "name": "conda-env-matflow_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
